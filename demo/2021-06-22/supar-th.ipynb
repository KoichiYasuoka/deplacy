{
  "nbformat":4,
  "nbformat_minor":0,
  "metadata":{
    "colab":{ "name":"世界のUniversal Dependenciesと係り受け解析ツール群" },
    "kernelspec":{ "name":"python3" },
    "accelerator": "GPU"
  },
  "cells":[
    {
      "cell_type":"markdown",
      "metadata":{ "colab_type":"text" },
      "source":[
        "# [世界のUniversal Dependenciesと係り受け解析ツール群](http://kanji.zinbun.kyoto-u.ac.jp/~yasuoka/publications/2021-06-22.pdf)\n",
        "## [タイ語UDを用いた係り受け解析器の自作](https://koichiyasuoka.github.io/deplacy/demo/2021-06-22/)\n",
        "### [SuPar](https://github.com/yzhangcs/parser)と[bert-base-thai](https://huggingface.co/monsoon-nlp/bert-base-thai)と[PyThaiNLP](https://github.com/PyThaiNLP/pythainlp)を用いる場合\n"
      ]
    },
    {
      "cell_type":"markdown",
      "metadata":{ "colab_type":"text" },
      "source":[
        "必要なパッケージと各conlluを準備"
      ]
    },
    {
      "cell_type":"code",
      "metadata":{ "colab_type":"code" },
      "source":[
        "!test -d UD_Thai-PUD || git clone --depth=1 https://github.com/universaldependencies/UD_Thai-PUD\n",
        "with open(\"UD_Thai-PUD/th_pud-ud-test.conllu\", \"r\", encoding=\"utf-8\") as f:\n",
        "  r=f.read()\n",
        "with open(\"train.conllu\", \"w\", encoding=\"utf-8\") as f1:\n",
        "  with open(\"test.conllu\", \"w\", encoding=\"utf-8\") as f2:\n",
        "    with open(\"dev.conllu\", \"w\", encoding=\"utf-8\") as f3:\n",
        "      f=[f1]*8+[f2, f3]\n",
        "      for i,s in enumerate(r.strip().split(\"\\n\\n\")):\n",
        "        print(s, \"\", sep=\"\\n\", file=f[i%len(f)])\n",
        "!pip install supar pythainlp deplacy"
      ]
    },
    {
      "cell_type":"markdown",
      "metadata":{ "colab_type":"text" },
      "source":[
        "my.suparを作成 (GPUで2時間程度)"
      ]
    },
    {
      "cell_type":"code",
      "metadata":{ "colab_type":"code" },
      "source":[
        "!biaffine-dep train -b -d 0 -c biaffine-dep-en -p my.supar -f bert --bert monsoon-nlp/bert-base-thai --embed= --train train.conllu --dev dev.conllu --test test.conllu"
      ]
    },
    {
      "cell_type":"markdown",
      "metadata":{ "colab_type":"text" },
      "source":[
        "my.suparで係り受け解析"
      ]
    },
    {
      "cell_type":"code",
      "metadata":{ "colab_type":"code" },
      "source":[
        "from supar import Parser\n",
        "prs = Parser.load(\"my.supar\")\n",
        "nlp = lambda x: prs.predict([x], lang=None).sentences[0]\n",
        "doc = nlp([\"ไม่\",\"เข้า\",\"ถ้า\",\"เสือ\",\"ย่อม\",\"ไม่\",\"ได้\",\"ลูก\",\"เสือ\"])\n",
        "print(doc)\n",
        "import deplacy\n",
        "deplacy.serve(doc,port=None)"
      ]
    },
    {
      "cell_type":"markdown",
      "metadata":{ "colab_type":"text" },
      "source":[
        "PyThaiNLPで単語切り"
      ]
    },
    {
      "cell_type":"code",
      "metadata":{ "colab_type":"code" },
      "source":[
        "from supar import Parser\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "prs = Parser.load(\"my.supar\")\n",
        "nlp = lambda x: prs.predict([word_tokenize(x)], lang=None).sentences[0]\n",
        "doc = nlp(\"ไม่เข้าถ้าเสือ ย่อมไม่ได้ลูกเสือ\")\n",
        "print(doc)\n",
        "import deplacy\n",
        "deplacy.serve(doc,port=None)"
      ]
    },
    {
      "cell_type":"markdown",
      "metadata":{ "colab_type":"text" },
      "source":[
        "UPOS・MISCを追加"
      ]
    },
    {
      "cell_type":"code",
      "metadata":{ "colab_type":"code" },
      "source":[
        "from supar import Parser\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.tag import pos_tag\n",
        "prs = Parser.load(\"my.supar\")\n",
        "def nlp(sentence):\n",
        "  s = word_tokenize(sentence)\n",
        "  d = prs.predict([[t for t in s if not t.isspace()]], lang=None).sentences[0]\n",
        "  d.values[3] = [p for t,p in pos_tag(s, corpus=\"orchid_ud\") if not t.isspace()]\n",
        "  m = [i-j-1 for j,i in enumerate([i for i,t in enumerate(s) if t.isspace()])]\n",
        "  d.values[9] = [\"_\" if i in m else \"SpaceAfter=No\" for i in range(len(s)-len(m))]\n",
        "  return d\n",
        "doc = nlp(\"ไม่เข้าถ้าเสือ ย่อมไม่ได้ลูกเสือ\")\n",
        "print(doc)\n",
        "import deplacy\n",
        "deplacy.serve(doc,port=None)"
      ]
    }
  ]
}
